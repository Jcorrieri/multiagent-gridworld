environment:
    map_name: empty
    max_steps: 4000
    size: 25
    num_agents: 10
    cr: 10

reward_scheme:
    new_tile_connected: 2.0
    new_tile_disconnected: -0.8
    old_tile_connected: -0.3
    old_tile_disconnected: -1.2
    obstacle: -1.0
    terminated: 480

training:
    gamma: 0.9
    lr: 0.0001
    grad_clip: 1.0
    train_batch_size: 2000
    num_epochs: 5
    minibatch_size: 200
    l2_regularization: 0.0001
    num_iterations: 8000